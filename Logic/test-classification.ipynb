{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a9c265d-21d6-4b81-803d-b5423b27ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import fasttext\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "import unidecode\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def preprocess_text(text, minimum_length=1, stopword_removal=True, stopwords_domain=[], lower_case=True,\n",
    "                    punctuation_removal=True):\n",
    "    \"\"\"\n",
    "    preprocess text by removing stopwords, punctuations, and converting to lowercase, and also filter based on a min length\n",
    "    for stopwords use nltk.corpus.stopwords.words('english')\n",
    "    for punctuations use string.punctuation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "        text to be preprocessed\n",
    "    minimum_length: int\n",
    "        minimum length of the token\n",
    "    stopword_removal: bool\n",
    "        whether to remove stopwords\n",
    "    stopwords_domain: list\n",
    "        list of stopwords to be removed base on domain\n",
    "    lower_case: bool\n",
    "        whether to convert to lowercase\n",
    "    punctuation_removal: bool\n",
    "        whether to remove punctuations\n",
    "    \"\"\"\n",
    "    if lower_case:\n",
    "        text = text.lower()\n",
    "    text = unidecode.unidecode(text)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'<br\\s*/?>', '', text)\n",
    "    text.strip()\n",
    "    if punctuation_removal:\n",
    "        translator = str.maketrans('', '', string.punctuation)\n",
    "        text = text.translate(translator)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update(stopwords_domain)\n",
    "    if stopword_removal:\n",
    "        new_text = ''\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = pos_tag(word_tokenize(text))\n",
    "        for token in tokens:\n",
    "            word, tag = token\n",
    "            if word not in stopwords_domain and len(word) > minimum_length:\n",
    "                wntag = tag[0].lower()\n",
    "                wntag = wntag if wntag in ['a', 'r', 'n', 'v'] else None\n",
    "                if not wntag:\n",
    "                    lemma = word\n",
    "                else:\n",
    "                    lemma = lemmatizer.lemmatize(word, wntag)\n",
    "\n",
    "                new_text = new_text + lemma + ' '\n",
    "        text = new_text\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "class FastText:\n",
    "    \"\"\"\n",
    "    A class used to train a FastText model and generate embeddings for text data.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    method : str\n",
    "        The training method for the FastText model.\n",
    "    model : fasttext.FastText._FastText\n",
    "        The trained FastText model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, method='skipgram'):\n",
    "        \"\"\"\n",
    "        Initializes the FastText with a preprocessor and a training method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        method : str, optional\n",
    "            The training method for the FastText model.\n",
    "        \"\"\"\n",
    "        self.method = method\n",
    "        self.model = None\n",
    "\n",
    "    def train(self, texts, text_file_path='data/FastText_data.txt', should_load_data=False):\n",
    "        \"\"\"\n",
    "        Trains the FastText model with the given texts.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        texts : list of str\n",
    "            The texts to train the FastText model.\n",
    "        \"\"\"\n",
    "        if should_load_data:\n",
    "            all_text = ''\n",
    "            for text in tqdm(texts):\n",
    "                all_text += text + '\\n'\n",
    "            with open(text_file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(all_text)\n",
    "                file.close()\n",
    "\n",
    "        self.model = fasttext.train_unsupervised(text_file_path, model=self.method)\n",
    "        print(\"Model trained successfully\")\n",
    "\n",
    "    def get_query_embedding(self, query):\n",
    "        \"\"\"\n",
    "        Generates an embedding for the given query.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        query : str\n",
    "            The query to generate an embedding for.\n",
    "        tf_idf_vectorizer : sklearn.feature_extraction.text.TfidfVectorizer\n",
    "            The TfidfVectorizer to transform the query.\n",
    "        do_preprocess : bool, optional\n",
    "            Whether to preprocess the query.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            The embedding for the query.\n",
    "        \"\"\"\n",
    "        preprocessed_query = preprocess_text(query)\n",
    "        return self.model.get_sentence_vector(preprocessed_query)\n",
    "\n",
    "    def analogy(self, word1, word2, word3):\n",
    "        \"\"\"\n",
    "        Perform an analogy task: word1 is to word2 as word3 is to __.\n",
    "\n",
    "        Args:\n",
    "            word1 (str): The first word in the analogy.\n",
    "            word2 (str): The second word in the analogy.\n",
    "            word3 (str): The third word in the analogy.\n",
    "\n",
    "        Returns:\n",
    "            str: The word that completes the analogy.\n",
    "        \"\"\"\n",
    "        # Obtain word embeddings for the words in the analogy\n",
    "        embedding1 = self.model[word1]\n",
    "        embedding2 = self.model[word2]\n",
    "        embedding3 = self.model[word3]\n",
    "\n",
    "        # Perform vector arithmetic\n",
    "        v = embedding3 + embedding2 - embedding1\n",
    "\n",
    "        # Create a dictionary mapping each word in the vocabulary to its corresponding vector\n",
    "        words = list(self.model.words.copy())\n",
    "\n",
    "        # Exclude the input words from the possible results\n",
    "        words = list(set(words).difference([word1, word2, word3]))\n",
    "\n",
    "        # Find the word whose vector is closest to the result vector\n",
    "        c_score = math.inf\n",
    "        chosen_vector = None\n",
    "        for word in words:\n",
    "            score = distance.cosine(v, self.model[word])\n",
    "            if score < c_score:\n",
    "                c_score = score\n",
    "                chosen_vector = word\n",
    "        return chosen_vector\n",
    "\n",
    "    def save_model(self, path='data/FastText_model.bin'):\n",
    "        \"\"\"\n",
    "        Saves the FastText model to a file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path : str, optional\n",
    "            The path to save the FastText model.\n",
    "        \"\"\"\n",
    "        self.model.save_model(path)\n",
    "\n",
    "    def load_model(self, path=\"data/FastText_model.bin\"):\n",
    "        \"\"\"\n",
    "        Loads the FastText model from a file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path : str, optional\n",
    "            The path to load the FastText model.\n",
    "        \"\"\"\n",
    "        self.model = fasttext.load_model(path)\n",
    "\n",
    "    def prepare(self, dataset, mode, save=False, path='/Users/divar/University/term-8/information-retrieval/imdb-mir-system/Logic/data/FastText_model.bin'):\n",
    "        \"\"\"\n",
    "        Prepares the FastText model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset : list of str\n",
    "            The dataset to train the FastText model.\n",
    "        mode : str\n",
    "            The mode to prepare the FastText model.\n",
    "        \"\"\"\n",
    "        if mode == 'train':\n",
    "            self.train(dataset)\n",
    "        if mode == 'load':\n",
    "            self.load_model(path)\n",
    "        if save:\n",
    "            self.save_model(path)\n",
    "\n",
    "class FastTextDataLoader:\n",
    "    \"\"\"\n",
    "    This class is designed to load and pre-process data for training a FastText model.\n",
    "\n",
    "    It takes the file path to a data source containing movie information (synopses, summaries, reviews, titles, genres) as input.\n",
    "    The class provides methods to read the data into a pandas DataFrame, pre-process the text data, and create training data (features and labels)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, preprocess, file_path='data/IMDB_crawled.json'):\n",
    "        \"\"\"\n",
    "        Initializes the FastTextDataLoader class with the file path to the data source.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path: str\n",
    "            The path to the file containing movie information.\n",
    "        \"\"\"\n",
    "        self.preprocess = preprocess\n",
    "        self.file_path = file_path\n",
    "        self.le = None\n",
    "        self.mapping = None\n",
    "\n",
    "    def read_data_to_df(self, should_ignore_empty_genres=True):\n",
    "        \"\"\"\n",
    "        Reads data from the specified file path and creates a pandas DataFrame containing movie information.\n",
    "\n",
    "        You can use an IndexReader class to access the data based on document IDs.\n",
    "        It extracts synopses, summaries, reviews, titles, and genres for each movie.\n",
    "        The extracted data is then stored in a pandas DataFrame with appropriate column names.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "            pd.DataFrame: A pandas DataFrame containing movie information (synopses, summaries, reviews, titles, genres).\n",
    "        \"\"\"\n",
    "        with open(self.file_path, 'r') as f:\n",
    "            documents = json.loads(f.read())\n",
    "            f.close()\n",
    "        data = []\n",
    "        for doc in tqdm(documents):\n",
    "            title = doc.get('title', '')\n",
    "            if title is None:\n",
    "                title = ''\n",
    "            synopsis = doc.get('synopsis', [])\n",
    "            if synopsis is None:\n",
    "                synopsis = []\n",
    "            summaries = doc.get('summaries', [])\n",
    "            if summaries is None:\n",
    "                summaries = []\n",
    "            reviews = doc.get('reviews', [])\n",
    "            if reviews is None:\n",
    "                reviews = []\n",
    "            genres = doc.get('genres', [])\n",
    "            if genres is None:\n",
    "                continue\n",
    "            # Check for empty records\n",
    "            if should_ignore_empty_genres and len(genres) == 0:\n",
    "                print(f'doc_id={doc[\"id\"]} has None genre!')\n",
    "                continue\n",
    "            if title == '' and len(synopsis) == len(summaries) == len(reviews) == 0:\n",
    "                print(f'doc_id={doc[\"id\"]} is None!')\n",
    "                continue\n",
    "            # Preprocess and add to df data\n",
    "            genres = genres[0]\n",
    "            data.append({\n",
    "                'title': self.preprocess(title),\n",
    "                'synopsis': self.preprocess(' '.join(synopsis)),\n",
    "                'summaries': self.preprocess(' '.join(summaries)),\n",
    "                'reviews': self.preprocess(' '.join(x[0] for x in ([['', '']] if reviews is None or len(reviews) == 0 else reviews))),\n",
    "                'genres': self.preprocess(genres),\n",
    "            })\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def create_train_data(self):\n",
    "        \"\"\"\n",
    "        Reads data using the read_data_to_df function, pre-processes the text data, and creates training data (features and labels).\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing two NumPy arrays: X (preprocessed text data) and y (encoded genre labels).\n",
    "        \"\"\"\n",
    "        df = self.read_data_to_df()\n",
    "        self.le = LabelEncoder()\n",
    "        df['genres'] = self.le.fit_transform(df['genres'])\n",
    "        self.mapping = dict(zip(range(len(self.le.classes_)), self.le.classes_))\n",
    "        df['text'] = df['synopsis'] + ' ' + df['summaries'] + ' ' + df['reviews'] + ' ' + df['title']\n",
    "        x = np.array(df['text'])\n",
    "        y = np.array(df['genres'])\n",
    "        return x, y\n",
    "\n",
    "class ReviewLoader:\n",
    "    def __init__(\n",
    "            self,\n",
    "            file_path: str = '/Users/divar/University/term-8/information-retrieval/imdb-mir-system/Logic/data/classification.pkl',\n",
    "            comments_path: str = '/Users/divar/University/term-8/information-retrieval/imdb-mir-system/Logic/data/comments_training.csv'\n",
    "    ):\n",
    "        self.file_path = file_path\n",
    "        self.comments_path = comments_path\n",
    "        self.df = None\n",
    "        self.fasttext_model = FastText()\n",
    "        self.fasttext_model.prepare(dataset=[], mode='load', save=False)\n",
    "        self.review_tokens = []\n",
    "        self.sentiments = []\n",
    "        self.embeddings = []\n",
    "\n",
    "    def save_data(self):\n",
    "        \"\"\"\n",
    "        Load the data from the csv file and preprocess the text. Then save the normalized tokens and the sentiment labels.\n",
    "        Also, load the fasttext model.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(self.comments_path)\n",
    "        self.df['review'] = self.df['review'].apply(preprocess_text)\n",
    "        self.df['review_embedding'] = self.df['review'].apply(self.fasttext_model.get_query_embedding)\n",
    "        mymap = {'positive': 1, 'negative': 0}\n",
    "        self.df['sentiment'] = self.df['sentiment'].apply(lambda s: mymap.get(s) if s in mymap else s)\n",
    "        self.df['review_embedding'] = self.df['review_embedding'].apply(list)\n",
    "        self.df.to_pickle(self.file_path)\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Load the data from the csv file and preprocess the text. Then save the normalized tokens and the sentiment labels.\n",
    "        Also, load the fasttext model.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_pickle(self.file_path)\n",
    "\n",
    "    def get_embeddings(self):\n",
    "        \"\"\"\n",
    "        Get the embeddings for the reviews using the fasttext model.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def split_data(self, test_data_ratio=0.2):\n",
    "        \"\"\"\n",
    "        Split the data into training and testing data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_data_ratio: float\n",
    "            The ratio of the test data\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray, np.ndarray, np.ndarray, np.ndarray\n",
    "            Return the training and testing data for the embeddings and the sentiments.\n",
    "            in the order of x_train, x_test, y_train, y_test\n",
    "        \"\"\"\n",
    "        threshold = int(test_data_ratio * self.df.shape[0])\n",
    "        train_df, test_df = train_test_split(self.df, test_size=threshold, random_state=42)\n",
    "        return (\n",
    "            train_df['review_embedding'].values, test_df['review_embedding'].values,\n",
    "            train_df['sentiment'].values, test_df['sentiment'].values\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f761699-c35f-4d5c-9e57-5a12fa51bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class BasicClassifier:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = None\n",
    "        self.path = model_path\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def predict(self, x):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def prediction_report(self, x, y):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def save(self):\n",
    "        with open(self.path, 'wb') as f:\n",
    "            pickle.dump(self.model, f)\n",
    "\n",
    "    def load(self):\n",
    "        with open(self.path, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "\n",
    "    def get_percent_of_positive_reviews(self, sentences):\n",
    "        \"\"\"\n",
    "        Get the percentage of positive reviews in the given sentences\n",
    "        Parameters\n",
    "        ----------\n",
    "        sentences: list\n",
    "            The list of sentences to get the percentage of positive reviews\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The percentage of positive reviews\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424d5549-4f2d-4ab6-a5f2-97eca7395d31",
   "metadata": {},
   "source": [
    "# Load Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f024db-268d-4053-9bb2-c77883bffe1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "loader = ReviewLoader()\n",
    "loader.load_data()\n",
    "x_train, x_test, y_train, y_test = loader.split_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ade7dbc-6d1e-4661-bbb8-2762ccd917fa",
   "metadata": {},
   "source": [
    "# KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6752ed7e-8ca2-40bc-bc8b-e8321eb41533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.spatial\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class KnnClassifierData:\n",
    "    def __init__(self):\n",
    "        self.k = None\n",
    "        self.pca = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "\n",
    "class KnnClassifier(BasicClassifier):\n",
    "    def __init__(self, n_neighbors):\n",
    "        super().__init__(\n",
    "            model_path='/Users/divar/University/term-8/information-retrieval/imdb-mir-system/'\n",
    "                       'Logic/data/classification/knn.pkl'\n",
    "        )\n",
    "        self.model = KnnClassifierData()\n",
    "        self.model.k = n_neighbors\n",
    "        self.model.pca = PCA(n_components=20)\n",
    "        self.model.X_train = None\n",
    "        self.model.y_train = None\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        Fit the model using X as training data and y as target values\n",
    "        use the Euclidean distance to find the k nearest neighbors\n",
    "        Warning: Maybe you need to reduce the size of X to avoid memory errors\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: np.ndarray\n",
    "            An m * n matrix - m is count of docs and n is embedding size\n",
    "        y: np.ndarray\n",
    "            The real class label for each doc\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "            Returns self as a classifier\n",
    "        \"\"\"\n",
    "        self.model.pca.fit(np.array(list(x)))\n",
    "        self.model.X_train = self.model.pca.transform(np.array(list(x)))\n",
    "        self.model.y_train = y\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: np.ndarray\n",
    "            An k * n matrix - k is count of docs and n is embedding size\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Return the predicted class for each doc\n",
    "            with the highest probability (argmax)\n",
    "        \"\"\"\n",
    "        x_reduced = self.model.pca.transform(np.array(list(x)))\n",
    "        predictions = []\n",
    "        for i in tqdm(range(len(x_reduced))):\n",
    "            d = []\n",
    "            votes = []\n",
    "            for j in range(len(self.model.X_train)):\n",
    "                dist = scipy.spatial.distance.euclidean(self.model.X_train[j], x_reduced[i])\n",
    "                d.append([dist, j])\n",
    "            d.sort()\n",
    "            d = d[0:self.model.k]\n",
    "            for d, j in d:\n",
    "                votes.append(y_train[j])\n",
    "            ans = Counter(votes).most_common(1)[0][0]\n",
    "            predictions.append(ans)\n",
    "        return predictions\n",
    "\n",
    "    def prediction_report(self, x, y):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: np.ndarray\n",
    "            An k * n matrix - k is count of docs and n is embedding size\n",
    "        y: np.ndarray\n",
    "            The real class label for each doc\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Return the classification report\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(x)\n",
    "        return classification_report(y, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "7fe0b310-42a6-4335-81ac-ffe88eb8f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KnnClassifier(n_neighbors=3)\n",
    "classifier.fit(x_train, y_train)\n",
    "classifier.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "50544844-cb20-4777-af6e-8fd3de65b1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10840168311c451c992938a844d5f41b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = classifier.prediction_report(x_test[:100], y_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "bda4272f-5b30-4ea3-b6f1-8b163509252a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74        48\n",
      "           1       0.78      0.67      0.72        52\n",
      "\n",
      "    accuracy                           0.73       100\n",
      "   macro avg       0.73      0.73      0.73       100\n",
      "weighted avg       0.74      0.73      0.73       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fda915-0a8c-4489-a672-4c656ff96d4a",
   "metadata": {},
   "source": [
    "# Deep NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "2eecf40e-4ce3-4adc-9595-c0161d234f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class ReviewDataSet(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = torch.FloatTensor(embeddings)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "\n",
    "        if len(self.embeddings) != len(self.labels):\n",
    "            raise Exception(\"Embeddings and Labels must have the same length\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.embeddings[i], self.labels[i]\n",
    "\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, in_features=100, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(in_features, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "\n",
    "class DeepModelClassifier(BasicClassifier):\n",
    "    def __init__(self, in_features, num_classes, batch_size, num_epochs=50):\n",
    "        \"\"\"\n",
    "        Initialize the model with the given in_features and num_classes\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_features: int\n",
    "            The number of input features\n",
    "        num_classes: int\n",
    "            The number of classes\n",
    "        batch_size: int\n",
    "            The batch size of dataloader\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            model_path='/Users/divar/University/term-8/information-retrieval/imdb-mir-system/'\n",
    "                       'Logic/data/classification/deep.pkl'\n",
    "        )\n",
    "        self.test_loader = None\n",
    "        self.in_features = in_features\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.model = MLPModel(in_features=in_features, num_classes=num_classes)\n",
    "        self.best_model = self.model.state_dict()\n",
    "        self.best_test_accuracy = 0\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        self.device = 'mps' if torch.backends.mps.is_available else 'cpu'\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else self.device\n",
    "        self.model.to(self.device)\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        Fit the model on the given train_loader and test_loader for num_epochs epochs.\n",
    "        You have to call set_test_dataloader before calling the fit function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: np.ndarray\n",
    "            The training embeddings\n",
    "        y: np.ndarray\n",
    "            The training labels\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        train_dataset = ReviewDataSet(x, y)\n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.model.train()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            total_loss = 0\n",
    "            with tqdm(enumerate(self.train_loader), total=len(self.train_loader)) as pbar:\n",
    "                for i, (embed, label) in pbar:\n",
    "                    embed = embed.to(self.device)\n",
    "                    label = label.to(self.device)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    output = self.model(embed)\n",
    "                    loss = self.criterion(output, label)\n",
    "                    total_loss += loss.item()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    pred = nn.functional.softmax(output, dim=0).argmax(dim=1)\n",
    "                    total += len(label)\n",
    "                    correct += torch.sum(pred == label).item()\n",
    "            print(\n",
    "                f'[Train]: epoch={epoch}, avg_acc={100 * (correct / total):.2f}, avg_loss={100 * (total_loss / total):.2f}')\n",
    "            f1, pred_label, true_label, eval_loss = self._eval_epoch(self.test_loader, self.model)\n",
    "            test_accuracy = (np.sum(np.array(true_label) == np.array(pred_label)).item()) / len(true_label)\n",
    "            if test_accuracy > self.best_test_accuracy:\n",
    "                self.best_test_accuracy = test_accuracy\n",
    "                self.best_model = self.model.state_dict()\n",
    "            print(f'[Test]: avg_acc={100 * (test_accuracy):.2f}, avg_loss={100 * (eval_loss / total):.2f}')\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Predict the labels on the given test_loader\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: np.ndarray\n",
    "            The test embeddings\n",
    "        Returns\n",
    "        -------\n",
    "        predicted_labels: list\n",
    "            The predicted labels\n",
    "        \"\"\"\n",
    "        x = torch.tensor(x).to(self.device)\n",
    "        output = self.model(x)\n",
    "        pred = nn.functional.softmax(output, dim=0).argmax(dim=1).cpu().numpy()\n",
    "        return pred\n",
    "\n",
    "    def _eval_epoch(self, dataloader: torch.utils.data.DataLoader, model):\n",
    "        \"\"\"\n",
    "        Evaluate the model on the given dataloader. used for validation and test\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataloader: torch.utils.data.DataLoader\n",
    "        Returns\n",
    "        -------\n",
    "        eval_loss: float\n",
    "            The loss on the given dataloader\n",
    "        predicted_labels: list\n",
    "            The predicted labels\n",
    "        true_labels: list\n",
    "            The true labels\n",
    "        f1_score_macro: float\n",
    "            The f1 score on the given dataloader\n",
    "        \"\"\"\n",
    "        print('Eval Model ...')\n",
    "        eval_loss = 0\n",
    "        total = 0\n",
    "        true_labels = []\n",
    "        pred_labels = []\n",
    "        with tqdm(enumerate(self.test_loader), total=len(self.test_loader)) as pbar:\n",
    "            for i, (embed, label) in pbar:\n",
    "                embed = embed.to(self.device)\n",
    "                label = label.to(self.device)\n",
    "                output = self.model(embed)\n",
    "                loss = self.criterion(output, label)\n",
    "                total += len(label)\n",
    "                eval_loss += loss.item()\n",
    "                pred_labels.append(nn.functional.softmax(output, dim=0).argmax(dim=1))\n",
    "                true_labels.append(label)\n",
    "        pred_labels = list(torch.cat(pred_labels).cpu())\n",
    "        true_labels = list(torch.cat(true_labels).cpu())\n",
    "        eval_loss /= total\n",
    "        f1 = f1_score(true_labels, pred_labels, average='macro')\n",
    "        return eval_loss, pred_labels, true_labels, f1\n",
    "\n",
    "    def set_test_dataloader(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Set the test dataloader. This is used to evaluate the model on the test set while training\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_test: np.ndarray\n",
    "            The test embeddings\n",
    "        y_test: np.ndarray\n",
    "            The test labels\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "            Returns self\n",
    "        \"\"\"\n",
    "        test_dataset = ReviewDataSet(X_test, y_test)\n",
    "        self.test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        return self\n",
    "\n",
    "    def prediction_report(self, x, y):\n",
    "        \"\"\"\n",
    "        Get the classification report on the given test set\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: np.ndarray\n",
    "            The test embeddings\n",
    "        y: np.ndarray\n",
    "            The test labels\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The classification report\n",
    "        \"\"\"\n",
    "        self.model.load_state_dict(self.best_model)\n",
    "        y_pred = self.predict(x)\n",
    "        return classification_report(y, y_pred, zero_division=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "24ca5962-0edc-4b55-a4b1-335e5cca9914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489240c1e74b442eb572d6a9c9b09e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=0, avg_acc=78.89, avg_loss=0.47\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd08e365f00f4f9b89bc1169f3e77199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=83.89, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0708f069eda6470c90c8c7a3de9d7ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=1, avg_acc=83.73, avg_loss=0.36\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a62fb9e5fd94b44bcc2f909de85b21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=83.90, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d86285b83d34f02b5e68e21a7b4328e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=2, avg_acc=84.17, avg_loss=0.34\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c0678345464a2f99f7c44faa6232ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=85.01, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c57e1f023741d1b9c294f46a25a4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=3, avg_acc=84.55, avg_loss=0.34\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ba047f87824809aee098c17ffaf5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=84.63, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d9e503b7674002b2ef48be1d2dfc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=4, avg_acc=84.69, avg_loss=0.34\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d652f38163945949ae8c050cbdf56ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=84.38, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2901ecf4024d4004ae3b0bc3fad5838d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=5, avg_acc=85.14, avg_loss=0.33\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a98f203ad06453f9d59de9899b2ba00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=85.07, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c09013010cc4aae86b3384175d1c7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=6, avg_acc=85.41, avg_loss=0.33\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5523833ad37c4863bcaf92c427ad67fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=85.48, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509122e96933410c9e1e26b2cb134f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=7, avg_acc=85.63, avg_loss=0.32\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903e944ef4204b98a7bdf0fe187a4c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=85.90, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1309bd66744a03ae00bfbd7a63abbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=8, avg_acc=86.08, avg_loss=0.32\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049f0e6fd87a4dd5b71292f27aac171d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.57, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828ce55b48b740dfb04c0227263ac511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=9, avg_acc=86.33, avg_loss=0.32\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d303c2892054557a8864958263b3d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.31, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4944673ee2486a85f8696cee4eef3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=10, avg_acc=86.41, avg_loss=0.32\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e24ccddda5494ea9a43eab4c3aedff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.76, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59adeae7a8574ae395d35f3a978f51ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=11, avg_acc=86.44, avg_loss=0.32\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f9b30bd23d44588a04c7a3ca296144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=85.20, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc78f86bc574d2ca782bb8f79e507df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=12, avg_acc=86.55, avg_loss=0.32\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24146b4dcc0e4a05a255715fc0416ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.61, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea154656f5714eb198c095dc1fc58621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=13, avg_acc=86.56, avg_loss=0.32\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1714235a7e4d45abaec9421121d03897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.43, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890c4b7a1637422fac1c06dc56129191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=14, avg_acc=86.65, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e347adb5734d9690536b7f2b719142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.61, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00d73f9270b4a47be1d341d4dc59b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=15, avg_acc=86.68, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb064c3412d48ea94d70e9f0757fbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.93, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7063e44b342a4ae5972aef9f131126c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=16, avg_acc=86.75, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020a48a3fb4a448992dc78f6f17fa18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.74, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2931fecb88694da8978ee3247e67df60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=17, avg_acc=86.71, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3d0421e1ab450e8a7206bcfe660957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.54, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81586a22c65406a830fd4337c725a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=18, avg_acc=86.92, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62e45d56b22474198fce529e9c9dd27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.67, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea14d66e485644ceacddbf322b364466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=19, avg_acc=86.81, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc8cf0b2e2a4605b373a588ed598eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.37, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9c12adcd14487aa09157ea60261572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=20, avg_acc=86.89, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4048e0907046a482347967f349e3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.77, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079ea4a301dd40fcbeb6cfc5e2b02a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=21, avg_acc=86.87, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0d805b93ce47b0939b5714f291c64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.22, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3baa6b33a64fb19affbdf81c65d40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=22, avg_acc=86.75, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562e6f3bf40c4ad898855e100bcbe57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.62, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daeac7e25fec440db6de1395719768e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=23, avg_acc=86.80, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9bad9061a847ecb4fdd949b9319676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.15, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddbab9b5b8b452a8ccf55fecbe03a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=24, avg_acc=86.98, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd5d9afd5d24865a2d77c8b2d4a693c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.70, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aad095f5ee94e1e91db5d85c670da6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=25, avg_acc=87.00, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d37a0d009a4c3c929ad13fc246263d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.60, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb77ed777aa4c7f8467d732e3279ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=26, avg_acc=86.91, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf96bfd450e149759c49c4e1fae14c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.72, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c922553c40444686b8b9f03d1f7f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=27, avg_acc=87.01, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14801a3293742729da6a24f32dfd300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.86, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6cae6b70174aa9b075878b698ecc98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=28, avg_acc=86.98, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73168ba0d3f846fd9043f6afd913f7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.47, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843e81a92bea4eb382f7779d7fc572f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=29, avg_acc=86.96, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35fff7a402a04db899bfadafd1b848db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.61, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16963605573d48f29f2696515c306667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=30, avg_acc=86.87, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51b33dd1190455c944596fbffa5973a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.88, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb6e4bd06424f03a1e998ba107eaf08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=31, avg_acc=86.97, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319f4ed0bbe94727978d44a5a2c9c979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.79, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f159266a8fc4225a510f78a155f41e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=32, avg_acc=87.08, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4812cc417f134ec7a72b40e6ec135b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.46, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd3cbf5f5964206adc5a6f2591c175c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=33, avg_acc=87.01, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2160b08c4a09422babc73e15d1bfeada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.80, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd169c80b0d4b8dadf08707b0efffaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=34, avg_acc=87.16, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf267e0bb5b43419cc1eb6e4d950b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.73, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b4601c86a14aa7a29186a20dc13406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=35, avg_acc=87.16, avg_loss=0.31\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c8d5569dc14d08aca08aa3ff54f42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.84, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702e55975c4149d595092199a5f25cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=36, avg_acc=87.00, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0924c975d448423f96fafd38c3ab3bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.75, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0918b581e44b4eafb244a2da29756bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=37, avg_acc=87.21, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342da572bb1e4bd1b0c34c75c66f819f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.65, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ab142f9b294522b503537c8480ad3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=38, avg_acc=87.19, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a281af65cd4881971b71280f889a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.49, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3b2b02508a4054877954f4fd728475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=39, avg_acc=87.27, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2dc3c73e0e745bf986a1e87bdca5fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.92, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4d5efc09d84caabf29fd92ad8bdc15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=40, avg_acc=87.36, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a214e135bd86469abf97ebdfe7f5dfe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.59, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0576e5757ae44f439ac55418f43567e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=41, avg_acc=87.17, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318f47fda4a64b828deb8c9d5efa3662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.60, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b71b7e2cfc74aa29b3f2e689fa7012e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=42, avg_acc=87.25, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1087a65f4074d229009ea901dd0bbe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.55, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff29ff2f20040cbbcb93ad0d7a3c37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=43, avg_acc=87.41, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e91d7d28a543ec81bd6f2119159d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.41, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a427c5812b14d53a4c6ecefdd78f58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=44, avg_acc=87.30, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc091adfc0740d89c33ff7ea96c1d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.77, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf466d140834f1d975fd966048037c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=45, avg_acc=87.56, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b23a194219d4e78b529f92fa1967786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=87.05, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede2e3d5741441e7af0e29accb2a3309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=46, avg_acc=87.29, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d5c0c09dc541a8a5302172d883fac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.31, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac768d1391a64fda9c2bb186c8af94bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=47, avg_acc=87.30, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f778f27d1747bebadc011587d7785d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.82, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74abf1f729c84e038b8db285621396f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=48, avg_acc=87.35, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330cf4760b7d4e278448a189521c9061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=86.63, avg_loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651be982169d475ab2dc28f1fe523b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: epoch=49, avg_acc=87.37, avg_loss=0.30\n",
      "Eval Model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1911fd966c094a31b8fa1aedec507c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]: avg_acc=87.00, avg_loss=0.00\n"
     ]
    }
   ],
   "source": [
    "classifier = DeepModelClassifier(in_features=100, num_classes=2, batch_size=100)\n",
    "classifier.set_test_dataloader(np.array(list(x_test)), y_test)\n",
    "classifier.fit(np.array(list(x_train)), y_train)\n",
    "classifier.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "755caabd-08a8-4b98-ae91-39d31001fbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      4961\n",
      "           1       0.88      0.87      0.88      5039\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = classifier.prediction_report(np.array(list(x_test)), y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298987d4-965a-4d55-9dfb-c321e7137045",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad1b1e9f-dc44-44fb-91a8-500856a229fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class NaiveBayes(BasicClassifier):\n",
    "    def __init__(self, count_vectorizer, alpha=1):\n",
    "        super().__init__(\n",
    "            model_path='/Users/divar/University/term-8/information-retrieval/imdb-mir-system/'\n",
    "                       'Logic/data/classification/naivebayes.pkl'\n",
    "        )\n",
    "        self.cv = count_vectorizer\n",
    "        self.num_classes = None\n",
    "        self.classes = None\n",
    "        self.number_of_features = None\n",
    "        self.number_of_samples = None\n",
    "        self.prior = None\n",
    "        self.feature_probabilities = None\n",
    "        self.log_probs = None\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        Fit the features and the labels\n",
    "        Calculate prior and feature probabilities\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: np.ndarray\n",
    "            An m * n matrix - m is count of docs and n is embedding size\n",
    "\n",
    "        y: np.ndarray\n",
    "            The real class label for each doc\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "            Returns self as a classifier\n",
    "        \"\"\"\n",
    "        self.classes = np.unique(y)\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.number_of_samples, self.number_of_features = x.shape\n",
    "        self.prior = []\n",
    "        for i in range(self.num_classes):\n",
    "            self.prior.append(sum(y == i) / self.number_of_samples)\n",
    "        self.feature_probabilities = np.zeros((self.num_classes, self.number_of_features))\n",
    "        for i in range(self.num_classes):\n",
    "            x_class = x[np.argwhere(y == i)]\n",
    "            num_words = np.sum(x_class, axis=0)\n",
    "            self.feature_probabilities[i, :] = (num_words + self.alpha) / (np.sum(x_class) + self.number_of_features)\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: np.ndarray\n",
    "            An k * n matrix - k is count of docs and n is embedding size\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Return the predicted class for each doc\n",
    "            with the highest probability (argmax)\n",
    "        \"\"\"\n",
    "        n, _ = x.shape\n",
    "        log_predict_probs = np.zeros((n, self.num_classes))\n",
    "        for i in range(self.num_classes):\n",
    "            log_predict_probs[:, i] += np.log(self.prior[i])\n",
    "            class_feature_prob = np.log(self.feature_probabilities[i, :].reshape(self.number_of_features, 1))\n",
    "            log_predict_probs[:, i] += (x @ class_feature_prob).squeeze()\n",
    "        return np.argmax(log_predict_probs, axis=1)\n",
    "\n",
    "    def prediction_report(self, x, y):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: np.ndarray\n",
    "            An k * n matrix - k is count of docs and n is embedding size\n",
    "        y: np.ndarray\n",
    "            The real class label for each doc\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Return the classification report\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(x)\n",
    "        return classification_report(y, y_pred)\n",
    "\n",
    "    def get_percent_of_positive_reviews(self, sentences):\n",
    "        \"\"\"\n",
    "        You have to override this method because we are using a different embedding method in this class.\n",
    "        \"\"\"\n",
    "        x = self.cv.transform(sentences).toarray()\n",
    "        pred = self.predict(x)\n",
    "        return sum(pred) / len(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba633168-b1b2-4567-a0c8-f987cf5262df",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = loader.df['review'].values[:20000]\n",
    "sentiments = loader.df['sentiment'].values[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dae7ecf-d564-49eb-a5a1-e3998e48a970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e7a052b-70e2-412c-bd77-26a2d602c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(reviews, sentiments, test_size=0.2, random_state=42)\n",
    "x_train = cv.transform(x_train).toarray()\n",
    "x_test = cv.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b8af290-5bce-4453-9b57-e7094a5118a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NaiveBayes at 0x2bcbb72b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = NaiveBayes(cv)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d45eea9-844e-4bbd-b227-89fd4ad01273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85      2048\n",
      "           1       0.86      0.82      0.84      1952\n",
      "\n",
      "    accuracy                           0.85      4000\n",
      "   macro avg       0.85      0.85      0.85      4000\n",
      "weighted avg       0.85      0.85      0.85      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = classifier.prediction_report(x_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90515f2f-27d0-4a0d-99e8-5000cbdd6fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de1d37-985e-40f6-87a5-48abd0c84840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
